{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d910eeeb",
   "metadata": {},
   "source": [
    "# Desafio 1: Análise do Momento de Vida da Empresa\n",
    "\n",
    "**Objetivo:** Identificar o momento de vida de uma empresa com base em seu comportamento financeiro transacional.\n",
    "\n",
    "**Etapas:**\n",
    "1. Carregamento e Preparação dos Dados\n",
    "2. Engenharia de Features\n",
    "3. Modelagem (Clusterização)\n",
    "4. Análise e Visualização dos Resultados\n",
    "5. Conclusão\n",
    "6. Comparação de Modelos Supervisionados\n",
    "7. Exportação de Dados para Power BI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d49ccb",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da3dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "df_id = pd.read_excel('data/Base1_ID.xlsx')\n",
    "df_transacoes = pd.read_excel('data/Base2_Transacoes.xlsx')\n",
    "\n",
    "df_id.rename(columns={'ID': 'id_empresa', 'VL_FATU': 'faturamento', 'DS_CNAE': 'setor_cnae', 'DT_REFE': 'data_referencia'}, inplace=True)\n",
    "df_transacoes.rename(columns={'ID_PGTO': 'id_pagador', 'ID_RCBE': 'id_recebedor', 'VL': 'valor_transacao', 'DS_TRAN': 'tipo_transacao', 'DT_REFE': 'data_transacao'}, inplace=True)\n",
    "df_id['data_referencia'] = pd.to_datetime(df_id['data_referencia'])\n",
    "df_transacoes['data_transacao'] = pd.to_datetime(df_transacoes['data_transacao'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d9aee",
   "metadata": {},
   "source": [
    "## 2. Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_unicos = pd.unique(np.concatenate((df_id['id_empresa'], df_transacoes['id_pagador'], df_transacoes['id_recebedor'])))\n",
    "df_empresas = pd.DataFrame(ids_unicos, columns=['id_empresa']).set_index('id_empresa')\n",
    "\n",
    "recebimentos = df_transacoes.groupby('id_recebedor').agg(total_recebido=('valor_transacao', 'sum'), num_transacoes_recebidas=('valor_transacao', 'count'), num_clientes_unicos=('id_pagador', 'nunique'))\n",
    "pagamentos = df_transacoes.groupby('id_pagador').agg(total_pago=('valor_transacao', 'sum'), num_transacoes_pagas=('valor_transacao', 'count'), num_fornecedores_unicos=('id_recebedor', 'nunique'))\n",
    "\n",
    "df_empresas = df_empresas.merge(recebimentos, left_index=True, right_index=True, how='left')\n",
    "df_empresas = df_empresas.merge(pagamentos, left_index=True, right_index=True, how='left')\n",
    "df_empresas.fillna(0, inplace=True)\n",
    "\n",
    "df_empresas['fluxo_caixa_liquido'] = df_empresas['total_recebido'] - df_empresas['total_pago']\n",
    "df_empresas['ticket_medio_recebido'] = df_empresas['total_recebido'] / df_empresas['num_transacoes_recebidas']\n",
    "df_empresas['ticket_medio_pago'] = df_empresas['total_pago'] / df_empresas['num_transacoes_pagas']\n",
    "df_empresas.fillna(0, inplace=True)\n",
    "\n",
    "df_id_info = df_id.set_index('id_empresa')[['faturamento', 'setor_cnae']].drop_duplicates()\n",
    "df_empresas = df_empresas.merge(df_id_info, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364099a",
   "metadata": {},
   "source": [
    "## 3. Modelagem (Clusterização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "features_numericas = df_empresas.select_dtypes(include=np.number).columns.tolist()\n",
    "df_modelo = df_empresas[features_numericas].copy()\n",
    "df_modelo.fillna(df_modelo.median(), inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dados_escalados = scaler.fit_transform(df_modelo)\n",
    "\n",
    "k_otimo = 4\n",
    "kmeans = KMeans(n_clusters=k_otimo, init='k-means++', n_init=10, random_state=42)\n",
    "df_empresas['cluster'] = kmeans.fit_predict(dados_escalados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d52fe",
   "metadata": {},
   "source": [
    "## 4. Análise e Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84381f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('--- Perfil Médio de Cada Cluster ---')\n",
    "perfil_clusters = df_empresas.groupby('cluster')[features_numericas].mean()\n",
    "print(perfil_clusters)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "componentes_principais = pca.fit_transform(dados_escalados)\n",
    "df_pca = pd.DataFrame(data=componentes_principais, columns=['PC1', 'PC2'])\n",
    "df_pca['cluster'] = df_empresas['cluster'].values\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='cluster', palette='viridis', s=50, alpha=0.7)\n",
    "plt.title('Visualização dos Clusters com PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d94ee",
   "metadata": {},
   "source": [
    "## 5. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supervised-intro",
   "metadata": {},
   "source": [
    "## 6. Comparação de Modelos Supervisionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supervised-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "X = dados_escalados\n",
    "y = df_empresas['cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "models = {\n",
    "    'Regressão Logística': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model_accuracy = results[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supervised-conclusion",
   "metadata": {},
   "source": [
    "### Conclusão da Análise Supervisionada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-intro",
   "metadata": {},
   "source": [
    "## 7. Exportação de Dados para Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_momento = {\n",
    "    0: 'Declínio',\n",
    "    1: 'Maturidade',\n",
    "    2: 'Expansão',\n",
    "    3: 'Início'\n",
    "}\n",
    "df_export = df_empresas.copy()\n",
    "df_export['momento_empresa'] = df_export['cluster'].map(mapa_momento)\n",
    "df_export = df_export.reset_index()\n",
    "output_path = 'data/dados_para_powerbi.csv'\n",
    "df_export.to_csv(output_path, index=False, sep=';', decimal=',')\n",
    "print(f'Dados exportados com sucesso para: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desafio2-title",
   "metadata": {},
   "source": [
    "# Desafio 2: Cadeias de Valor e Análise de Redes\n\n",
    "Neste desafio, vamos analisar a rede de transações entre as empresas para identificar padrões de relacionamento, empresas centrais (hubs) e comunidades. Usaremos a biblioteca `networkx` para modelar e analisar a rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desafio2-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx==3.1\n",
    "!pip install python-louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desafio2-graph-title",
   "metadata": {},
   "source": [
    "## 8. Construção do Grafo de Transações\n\n",
    "Vamos modelar as transações como um grafo direcionado, onde cada empresa é um nó e uma aresta representa o fluxo financeiro (pagamento) de uma empresa para outra. O peso das arestas será o valor total transacionado e o número de transações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desafio2-graph-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n\n",
    "df_arestas = df_transacoes.groupby(['id_pagador', 'id_recebedor']).agg(\n",
    "    valor_total=('valor_transacao', 'sum'),\n",
    "    num_transacoes=('valor_transacao', 'count')\n",
    f`).reset_index()\n\n",
    "G = nx.from_pandas_edgelist(\n",
    "    df_arestas, \n",
    "    source='id_pagador', \n",
    "    target='id_recebedor', \n",
    "    edge_attr=['valor_total', 'num_transacoes'], \n",
    "    create_using=nx.DiGraph()\n",
    f`)

",
    "print(f'Grafo criado com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desafio2-metrics-title",
   "metadata": {},
   "source": [
    "## 9. Análise de Centralidade e Detecção de Comunidades\n\n",
    "Agora, vamos calcular métricas de rede para identificar as empresas mais influentes e detectar comunidades (grupos de empresas com alta interconexão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desafio2-metrics-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from community import community_louvain\n\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "in_degree_centrality = nx.in_degree_centrality(G)\n",
    "out_degree_centrality = nx.out_degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, k=1000, seed=42)\n\n",
    "partition = community_louvain.best_partition(G.to_undirected(), random_state=42)\n\n",
    "df_rede = pd.DataFrame(G.nodes(), columns=['id_empresa'])\n",
    "df_rede['degree_centrality'] = df_rede['id_empresa'].map(degree_centrality)\n",
    "df_rede['in_degree_centrality'] = df_rede['id_empresa'].map(in_degree_centrality)\n",
    "df_rede['out_degree_centrality'] = df_rede['id_empresa'].map(out_degree_centrality)\n",
    "df_rede['betweenness_centrality'] = df_rede['id_empresa'].map(betweenness_centrality)\n",
    "df_rede['comunidade'] = df_rede['id_empresa'].map(partition)\n",
    "df_rede.set_index('id_empresa', inplace=True)\n\n",
    "print('Métricas de rede calculadas com sucesso.')\n",
    "df_rede.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desafio2-analysis-title",
   "metadata": {},
   "source": [
    "## 10. Análise dos Resultados da Rede\n\n",
    "Vamos analisar as empresas com maiores métricas de centralidade e a distribuição das comunidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desafio2-analysis-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Top 10 Empresas por Grau de Centralidade (Hubs) ---')\n",
    "print(df_rede.sort_values(by='degree_centrality', ascending=False).head(10))\n",
    "print('\n' + '-'*50 + '\n')\n\n",
    "print('--- Top 10 Empresas por Centralidade de Intermediação (Pontes) ---')\n",
    "print(df_rede.sort_values(by='betweenness_centrality', ascending=False).head(10))\n",
    "print('\n' + '-'*50 + '\n')\n\n",
    "print('--- Distribuição do Tamanho das Comunidades ---')\n",
    "print(df_rede['comunidade'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desafio2-export-title",
   "metadata": {},
   "source": [
    "## 11. Exportação dos Dados da Análise de Rede\n\n",
    "Finalmente, vamos exportar os dados da análise de rede para um arquivo CSV, que pode ser usado para visualizações mais avançadas no Power BI, Gephi ou outra ferramenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desafio2-export-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rede_completo = df_empresas.join(df_rede, how='left')\n",
    "df_rede_completo['comunidade'] = df_rede_completo['comunidade'].fillna(-1).astype(int)\n\n",
    "df_export_rede = df_rede_completo.reset_index()\n\n",
    "output_path_rede = 'data/dados_rede_para_powerbi.csv'\n\n",
    "df_export_rede.to_csv(output_path_rede, index=False, sep=';', decimal=',')\n\n",
    "print(f'Dados da análise de rede exportados com sucesso para: {output_path_rede}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}